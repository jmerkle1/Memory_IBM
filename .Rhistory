tck=-0.02, cex.axis=.8)
plot(results$t, results$pop.size, type="l",ylab="N", xlab="Time step", lwd=3)
plot(results$t, results$births, type="l",ylab="Births", xlab="Time step", lwd=3)
plot(results$t, results$deaths, type="l",ylab="Deaths", xlab="Time step", lwd=3)
plot(results$t, results$med.age, type="l",ylab="Median age", xlab="Time step", lwd=3)
plot(results$t, results$frac.informed, type="l",
ylim=c(0,1),ylab="Proportion", xlab="Time step", lwd=3)
lines(results$t, 1-results$frac.informed, col="grey",lwd=3)
legend("right", c("Informed","Uninformed"), lty=1, col=c("black","grey"), inset=0.02)
dev.off()
str(interactions[[1]])
rowSums(interactions[[2]])
#histogram of number of individuals with a number of interactions, interactions are binned in intervals of 5
sumIndInteracts <- rowSums(interactions[[2]])
hist(sumIndInteracts)
#plot of one yrs interactions
interactGraph <- graph_from_incidence_matrix(interactions[[2]], multiple = FALSE, mode="all", weighted = TRUE)
plot(interactGraph, vertex.size=10, vertex.label=NA)
as.matrix(interactions[[2]])
#source the functions you will need
source("C:/Users/jmerkle/Documents/GitHub/Memory_IBM/info.transfer.IBM.R")
info.transfer.IBM(h=0.10, #increase in probability of death for uninformed
nl=0.01, # naive learning probability of the oldest animals (i.e., the ones that have the highest naive learning)
si=5, # maximum mean (i.e., lambda of poison distribution) number of interactions per pair (if animal has 1 bold, it interacts with an animal with 1 boldness, and population is at or above K, this is the lambda of the interaction distributions)
infotransfer=0.6, # given an interaction, what is the probability that information is transfered (min=0, max=1)
K=100, # carrying capacity
N0=50, # starting number of individuals
t=10, # time of simulation
sex.ratio=0.5, #what is the sex ratio of of the population/births?
age.distr.lamba=5, # lambda value for starting age distribution based on poison distribution
informed.distr.beta=c(.5, 1), # probability of knowing information, beta distribution ranges from 0 to 1 (vector of 2 values: shape1 and shape2)
bold.distr.beta=c(2, 2), # probability of being bold, beta distribution (vector of 2 values: shape1 and shape2)
birthdeath.file="C:/Users/jmerkle/Documents/GitHub/Memory_IBM/ageClass_Test.csv", #dataframe of age based birth and death rate. The columns should be age, ageClass, birthRate, and survivalRate, in that order.
result.folder="C:/Users/jmerkle/Desktop/results", #an empty folder where results will be saved.
set_seed=FALSE, # want to make results reproducible? Then set as TRUE
save_at_each_iter=TRUE, #should all results be written to file at each time step?
vertTransmission=0) #0 if false, 1 if true, vertical transmission of info status
# load up results files
result.folder="C:/Users/jmerkle/Desktop/results"
load(paste0(result.folder,"/interaction_matricies.RData"))
load(paste0(result.folder,"/population_data.RData"))  #don't really need this if ind data is written out
load(paste0(result.folder,"/individual_data.RData"))
results <- read.csv(paste0(result.folder,"/population_stats.csv"))
head(results)
# png(paste0(result.folder,"/summary_stats.png"), width=4, height=6, units="in", res=400)
par(mfrow=c(3,2), mai=c(.3,.3,.03,.03), mgp=c(1,.1,0),
tck=-0.02, cex.axis=.8)
plot(results$t, results$pop.size, type="l",ylab="N", xlab="Time step", lwd=3)
plot(results$t, results$births, type="l",ylab="Births", xlab="Time step", lwd=3)
plot(results$t, results$deaths, type="l",ylab="Deaths", xlab="Time step", lwd=3)
plot(results$t, results$med.age, type="l",ylab="Median age", xlab="Time step", lwd=3)
plot(results$t, results$frac.informed, type="l",
ylim=c(0,1),ylab="Proportion", xlab="Time step", lwd=3)
lines(results$t, 1-results$frac.informed, col="grey",lwd=3)
legend("right", c("Informed","Uninformed"), lty=1, col=c("black","grey"), inset=0.02)
#plot of one yrs interactions
interactGraph <- graph_from_incidence_matrix(interactions[[2]], multiple = FALSE, mode="all", weighted = TRUE)
plot(interactGraph, vertex.size=10, vertex.label=NA)
dev.off()
summary(interactGraph)
head(interactions[[2]])
plot(interactGraph, vertex.size=10, vertex.label=NA)
#plot of one yrs interactions
interactGraph <- graph_from_incidence_matrix(interactions[[2]], multiple = FALSE, directed=FALSE, weighted = TRUE)
summary(interactGraph)
plot(interactGraph, vertex.size=10, vertex.label=NA)
E(interactGraph)$width
E(interactGraph)$weight
dim(interactions[[2]]\)
dim(interactions[[2]]\)
dim(interactions[[2]])
head(as.matrix(interactions[[2]]))
V(interactGraph)
V(interactGraph)$weight
50*50
E(interactGraph)
length(E(interactGraph)$weight)
hist(E(interactGraph)$weight)
E(interactGraph)
V(interactGraph)$name
V(interactGraph)
tmp <- as.matrix(interactions[[2]])
View(tmp)
matrix(sample(0:1, 15, repl=TRUE), 3, 5)
inc <- matrix(sample(0:1, 15, repl=TRUE), 3, 5)
colnames(inc) <- letters[1:5]
rownames(inc) <- LETTERS[1:3]
graph_from_incidence_matrix(inc)
V(graph_from_incidence_matrix(inc))
#plot of one yrs interactions
interactGraph <- graph_from_data_frame(interactions[[2]], diag = FALSE, mode="undirected", weighted = TRUE)
#plot of one yrs interactions
interactGraph <- graph_from_adjacency_matrix(interactions[[2]], diag = FALSE, mode="undirected", weighted = TRUE)
summary(interactGraph)
plot(interactGraph, vertex.size=10, vertex.label=NA)
length(E(interactGraph)$weight)   #this is the number of edges
hist(E(interactGraph)$weight)    #this is the distribution of interactions or weights among the number of edges
E(interactGraph)   # Here are the edges
V(interactGraph)
plot(interactGraph, vertex.size=10, vertex.label=NA)
length(E(interactGraph)$weight)   #this is the number of edges
hist(E(interactGraph)$weight)    #this is the distribution of interactions or weights among the number of edges
E(interactGraph)   # Here are the edges
length(V(interactGraph)) # this is the number of vertices or individuals in teh graph
#histogram of number of individuals with a number of interactions, interactions are binned in intervals of 5
sumIndInteracts <- rowSums(interactions[[2]])
hist(sumIndInteracts)
plot(interactGraph, vertex.size=10, vertex.label=NA)
lo <- layout_nicely(interactGraph)
plot(interactGraph, layout=lo)
plot(interactGraph, layout=lo, vertex.label.cex=.6, edge.curved=.1)
lo <- layout_nicely(interactGraph, dim=3)
plot(interactGraph, layout=lo, vertex.label.cex=.6, edge.curved=.1)
lo <- layout_with_dh(interactGraph)
plot(interactGraph, layout=lo, vertex.label.cex=.6, edge.curved=.1)
lo <- layout_with_fr(interactGraph)
plot(interactGraph, layout=lo, vertex.label.cex=.6, edge.curved=.1)
lo <- layout_with_gem(interactGraph)
plot(interactGraph, layout=lo, vertex.label.cex=.6, edge.curved=.1)
lo <- layout_nicely(interactGraph)
plot(interactGraph, layout=lo, vertex.label.cex=.6, edge.curved=.1)
plot(interactGraph, layout=lo, vertex.label.cex=.6, edge.curved=.1, mai=c(.1,.1,.1,.1))
lo <- layout_nicely(interactGraph)
par(mai=c(.1,.1,.1,.1))
plot(interactGraph, layout=lo, vertex.label.cex=.6, edge.curved=.1)
plot(interactGraph, layout=lo, vertex.label.cex=.6, vertex.size=10, edge.curved=.1)
E(interactGraph)$width <- E(interactGraph)$weight
plot(g, main=paste("Annual:",yrs[i]),vertex.label.cex=.6, vertex.label.color="black",
edge.curved=.1, layout=lo)
plot(interactGraph, layout=lo, vertex.label.cex=.6, vertex.size=10, edge.curved=.1)
#plotting
E(interactGraph)$width <- E(interactGraph)$weight
lo <- layout_nicely(interactGraph)
par(mai=c(.1,.1,.1,.1))
plot(interactGraph, layout=lo, vertex.label.cex=.6, vertex.size=10, edge.curved=.1)
#plotting
E(interactGraph)$width <- E(interactGraph)$weight*2
lo <- layout_nicely(interactGraph)
par(mai=c(.1,.1,.1,.1))
plot(interactGraph, layout=lo, vertex.label.cex=.6, vertex.size=10, edge.curved=.1)
plot(interactGraph, layout=lo, vertex.label.cex=.6, vertex.size=10, edge.curved=.3)
edge_density(interactGraph) #The proportion of present edges from all possible edges in the network.
mean_distance(interactGraph)
diameter(interactGraph, directed=F, weights=E(interactGraph)$weight)
diameter(interactGraph, directed=F, weights=NULL)
mean_distance(interactGraph)
degree(interactGraph)
betweenness(interactGraph)    #the number of geodesics (shortest paths) going through a vertex or an edge.
mean(betweenness(interactGraph))    #the number of geodesics (shortest paths) going through a vertex or an edge.
eigen_centrality(interactGraph, weights=E(interactGraph)$weight)$value
eigen_centrality(interactGraph, weights=E(interactGraph)$weight)$value    # mean centrality proportional to the sum of connection centralities
hub.score(interactGraph)$vector   #hub or authority score
hub.score(interactGraph)$value   #hub or authority score
hub.score(interactGraph, weights=E(interactGraph)$weight)$value   #hub or authority score
transitivity(interactGraph)
transitivity(interactGraph, type="global")
transitivity(interactGraph, type="global", weights=E(interactGraph)$weight)
results
length(interactions)
# add network matricies to results table
results.graph <- do.call(rbind, lapply(1:length(interactions), function(i){
tmp <- interactions[[i]]
g <- graph_from_adjacency_matrix(tmp, diag = FALSE, mode="undirected", weighted = TRUE)
return(data.frame(t=i-1,edge_density=edge_density(g), #The proportion of present edges from all possible edges in the network.
diameter=diameter(g, directed=F, weights=NULL),   #  length of the longest geodesic (or longest distance)
mean_distance=mean_distance(g),            # mean length of geodesics
degree=degree(g),
betweenness=mean(betweenness(g)),    #the mean number of geodesics (shortest paths) going through a vertex or an edge.
eigen_centrality=eigen_centrality(g, weights=E(g)$weight)$value,    # mean centrality proportional to the sum of connection centralities
authority=hub.score(g, weights=E(g)$weight)$value,   #hub or authority score
transitivity=transitivity(g, type="global", weights=E(g)$weight)))   #probability that the adjacent vertices of a vertex are connected. This is sometimes also called the clustering coefficient.
}))
head(results.graph)
1:length(interactions)
results.graph
i=1
edge_density(g)
tmp <- interactions[[i]]
g <- graph_from_adjacency_matrix(tmp, diag = FALSE, mode="undirected", weighted = TRUE)
edge_density(g)
tmp
# add network matricies to results table
results.graph <- do.call(rbind, lapply(2:length(interactions), function(i){
tmp <- interactions[[i]]
g <- graph_from_adjacency_matrix(tmp, diag = FALSE, mode="undirected", weighted = TRUE)
return(data.frame(t=i-1,edge_density=edge_density(g), #The proportion of present edges from all possible edges in the network.
diameter=diameter(g, directed=F, weights=NULL),   #  length of the longest geodesic (or longest distance)
mean_distance=mean_distance(g),            # mean length of geodesics
degree=degree(g),
betweenness=mean(betweenness(g)),    #the mean number of geodesics (shortest paths) going through a vertex or an edge.
eigen_centrality=eigen_centrality(g, weights=E(g)$weight)$value,    # mean centrality proportional to the sum of connection centralities
authority=hub.score(g, weights=E(g)$weight)$value,   #hub or authority score
transitivity=transitivity(g, type="global", weights=E(g)$weight)))   #probability that the adjacent vertices of a vertex are connected. This is sometimes also called the clustering coefficient.
}))
head(results.graph)
i=1
i=2
tmp <- interactions[[i]]
g <- graph_from_adjacency_matrix(tmp, diag = FALSE, mode="undirected", weighted = TRUE)
edge_density(g)
diameter(g, directed=F, weights=NULL)
mean_distance(g)
degree(g)
mean(betweenness(g))
eigen_centrality(g, weights=E(g)$weight)$value
hub.score(g, weights=E(g)$weight)$value
transitivity(g, type="global", weights=E(g)$weight)
V(g)
# add network matricies to results table
results.graph <- do.call(rbind, lapply(2:length(interactions), function(i){
tmp <- interactions[[i]]
g <- graph_from_adjacency_matrix(tmp, diag = FALSE, mode="undirected", weighted = TRUE)
return(data.frame(t=i-1, no_ids=length(V(g)),
edge_density=edge_density(g), #The proportion of present edges from all possible edges in the network.
diameter=diameter(g, directed=F, weights=NULL),   #  length of the longest geodesic (or longest distance)
mean_distance=mean_distance(g),            # mean length of geodesics
degree=mean(degree(g)),
betweenness=mean(betweenness(g)),    #the mean number of geodesics (shortest paths) going through a vertex or an edge.
eigen_centrality=eigen_centrality(g, weights=E(g)$weight)$value,    # mean centrality proportional to the sum of connection centralities
authority=hub.score(g, weights=E(g)$weight)$value,   #hub or authority score
transitivity=transitivity(g, type="global", weights=E(g)$weight)))   #probability that the adjacent vertices of a vertex are connected. This is sometimes also called the clustering coefficient.
}))
head(results.graph)
# png(paste0(result.folder,"/summary_stats.png"), width=4, height=6, units="in", res=400)
par(mfrow=c(4,4), mai=c(.3,.3,.03,.03), mgp=c(1,.1,0),
tck=-0.02, cex.axis=.8)
# png(paste0(result.folder,"/summary_graph_stats.png"), width=6, height=6, units="in", res=400)
par(mfrow=c(4,4), mai=c(.3,.3,.03,.03), mgp=c(1,.1,0),
tck=-0.02, cex.axis=.8)
for(i in 3:ncol(results.graph)){
plot(results.graph[,1], results.graph[,i], type="l",ylab="N", xlab=names(results.graph)[i], lwd=3)
}
# png(paste0(result.folder,"/summary_graph_stats.png"), width=6, height=6, units="in", res=400)
par(mfrow=c(4,2), mai=c(.3,.3,.03,.03), mgp=c(1,.1,0),
tck=-0.02, cex.axis=.8)
for(i in 3:ncol(results.graph)){
plot(results.graph[,1], results.graph[,i], type="l",ylab="Time step", ylab=names(results.graph)[i], lwd=3)
}
# png(paste0(result.folder,"/summary_graph_stats.png"), width=6, height=6, units="in", res=400)
par(mfrow=c(4,2), mai=c(.3,.3,.03,.03), mgp=c(1,.1,0),
tck=-0.02, cex.axis=.8)
for(i in 3:ncol(results.graph)){
plot(results.graph[,1], results.graph[,i], type="l",xlab="Time step", ylab=names(results.graph)[i], lwd=3)
}
# png(paste0(result.folder,"/summary_graph_stats.png"), width=3.2, height=6, units="in", res=400)
par(mfrow=c(4,2), mai=c(.3,.3,.03,.03), mgp=c(1,.1,0),
tck=-0.02, cex.axis=.8)
for(i in 3:ncol(results.graph)){
plot(results.graph[,1], results.graph[,i], type="l",xlab="Time step", ylab=names(results.graph)[i], lwd=3)
}
# png(paste0(result.folder,"/summary_graph_stats.png"), width=3.2, height=6, units="in", res=400)
par(mfrow=c(3,3), mai=c(.3,.3,.03,.03), mgp=c(1,.1,0),
tck=-0.02, cex.axis=.8)
for(i in 2:ncol(results.graph)){
plot(results.graph[,1], results.graph[,i], type="l",xlab="Time step", ylab=names(results.graph)[i], lwd=3)
}
# add network matricies to results table
results.graph <- do.call(rbind, lapply(2:length(interactions), function(i){
tmp <- interactions[[i]]
g <- graph_from_adjacency_matrix(tmp, diag = FALSE, mode="undirected", weighted = TRUE)
return(data.frame(t=i-1, no_ids=length(V(g)),
edge_density=edge_density(g), #The proportion of present edges from all possible edges in the network.
diameter=diameter(g, directed=F, weights=NULL),   #  length of the longest geodesic (or longest distance)
mean_distance=mean_distance(g),            # mean length of geodesics
degree=mean(degree(g, normalized=TRUE)),
betweenness=mean(betweenness(g)),    #the mean number of geodesics (shortest paths) going through a vertex or an edge.
eigen_centrality=eigen_centrality(g, weights=E(g)$weight)$value,    # mean centrality proportional to the sum of connection centralities
authority=hub.score(g, weights=E(g)$weight)$value,   #hub or authority score
transitivity=transitivity(g, type="global", weights=E(g)$weight)))   #probability that the adjacent vertices of a vertex are connected. This is sometimes also called the clustering coefficient.
}))
# main plotting of graph results over time
# png(paste0(result.folder,"/summary_graph_stats.png"), width=5, height=5, units="in", res=400)
par(mfrow=c(3,3), mai=c(.3,.3,.03,.03), mgp=c(1,.1,0),
tck=-0.02, cex.axis=.8)
for(i in 2:ncol(results.graph)){
plot(results.graph[,1], results.graph[,i], type="l",xlab="Time step", ylab=names(results.graph)[i], lwd=3)
}
# add network matricies to results table
results.graph <- do.call(rbind, lapply(2:length(interactions), function(i){
tmp <- interactions[[i]]
g <- graph_from_adjacency_matrix(tmp, diag = FALSE, mode="undirected", weighted = TRUE)
return(data.frame(t=i-1, no_ids=length(V(g)),
edge_density=edge_density(g), #The proportion of present edges from all possible edges in the network.
diameter=diameter(g, directed=F, weights=NULL),   #  length of the longest geodesic (or longest distance)
mean_distance=mean_distance(g),            # mean length of geodesics
degree=mean(degree(g, normalized=TRUE)),
betweenness=mean(betweenness(g, normalized=TRUE)),    #the mean number of geodesics (shortest paths) going through a vertex or an edge.
eigen_centrality=eigen_centrality(g, weights=E(g)$weight, scale=TRUE)$value,    # mean centrality proportional to the sum of connection centralities
authority=hub.score(g, weights=E(g)$weight, scale=TRUE)$value,   #hub or authority score
transitivity=transitivity(g, type="global", weights=E(g)$weight)))   #probability that the adjacent vertices of a vertex are connected. This is sometimes also called the clustering coefficient.
}))
head(results.graph)
# main plotting of graph results over time
# png(paste0(result.folder,"/summary_graph_stats.png"), width=5, height=5, units="in", res=400)
par(mfrow=c(3,3), mai=c(.3,.3,.03,.03), mgp=c(1,.1,0),
tck=-0.02, cex.axis=.8)
for(i in 2:ncol(results.graph)){
plot(results.graph[,1], results.graph[,i], type="l",xlab="Time step", ylab=names(results.graph)[i], lwd=3)
}
# main plotting of graph results over time
png(paste0(result.folder,"/summary_graph_stats.png"), width=5, height=5, units="in", res=400)
par(mfrow=c(3,3), mai=c(.3,.3,.03,.03), mgp=c(1,.1,0),
tck=-0.02, cex.axis=.8)
for(i in 2:ncol(results.graph)){
plot(results.graph[,1], results.graph[,i], type="l",xlab="Time step", ylab=names(results.graph)[i], lwd=3)
}
dev.off()
info.transfer.IBM(h=0.10, #increase in probability of death for uninformed
nl=0.01, # naive learning probability of the oldest animals (i.e., the ones that have the highest naive learning)
si=5, # maximum mean (i.e., lambda of poison distribution) number of interactions per pair (if animal has 1 bold, it interacts with an animal with 1 boldness, and population is at or above K, this is the lambda of the interaction distributions)
infotransfer=0.6, # given an interaction, what is the probability that information is transfered (min=0, max=1)
K=100, # carrying capacity
N0=50, # starting number of individuals
t=25, # time of simulation
sex.ratio=0.5, #what is the sex ratio of of the population/births?
age.distr.lamba=5, # lambda value for starting age distribution based on poison distribution
informed.distr.beta=c(.5, 1), # probability of knowing information, beta distribution ranges from 0 to 1 (vector of 2 values: shape1 and shape2)
bold.distr.beta=c(2, 2), # probability of being bold, beta distribution (vector of 2 values: shape1 and shape2)
birthdeath.file="C:/Users/jmerkle/Documents/GitHub/Memory_IBM/ageClass_Test.csv", #dataframe of age based birth and death rate. The columns should be age, ageClass, birthRate, and survivalRate, in that order.
result.folder="C:/Users/jmerkle/Desktop/results", #an empty folder where results will be saved.
set_seed=FALSE, # want to make results reproducible? Then set as TRUE
save_at_each_iter=TRUE, #should all results be written to file at each time step?
vertTransmission=0) #0 if false, 1 if true, vertical transmission of info status
#source the function
source("C:/Users/jmerkle/Documents/GitHub/Memory_IBM/info.transfer.IBM.R")
info.transfer.IBM <- function(h=0.20, #increase in probability of death for uninformed
nl=0.01, # naive learning probability of the oldest animals (i.e., the ones that have the highest naive learning)
si=5, # maximum mean (i.e., lambda of poison distribution) number of interactions per pair (if animal has 1 bold, it interacts with an animal with 1 boldness, and population is at or above K, this is the lambda of the interaction distributions)
infotransfer=0.03, # given an interaction, what is the probability that information is transfered (min=0, max=1)
K=200, # carrying capacity
N0=50, # starting number of individuals
t=25, # how many years should the simulation run for?
sex.ratio=0.5, #what is the sex ratio of of the population/births?
age.distr.lamba=4, # lambda value for starting age distribution based on poison distribution
informed.distr.beta=c(.5, 5), # starting probability distribution of knowing information; beta distribution ranges from 0 to 1 (vector of 2 values: shape1 and shape2)
bold.distr.beta=c(2, 5), # starting probability distribution of being bold, beta distribution (vector of 2 values: shape1 and shape2)
birthdeath.file="C:/Users/jmerkle/Documents/GitHub/Memory_IBM/ageClass_Test.csv", #dataframe of age based birth and death rate for FEMALES only. The columns should be age, ageClass, birthRate, and survivalRate, in that order.
result.folder="C:/Users/jmerkle/Desktop/results", #an empty folder where results will be saved.
set_seed=FALSE, # want to make results reproducible? Then set as TRUE
save_at_each_iter=TRUE, #should all results be written to file at each time step?
vertTransmission=1){ # When giving birth, should your information status be given to your offspring? 0 if false, 1 if true (i.e., is there vertical transmission of information?)
#manage packages
if(all(c("igraph","Matrix") %in% installed.packages()[,1])==FALSE)
stop("You must install the following packages: igraph and Matrix.")
require(igraph)
require(Matrix)
#identify initial time
t1 <- Sys.time()
print(paste0("start time: ",t1,"."))
#check the empty directories
if(dir.exists(result.folder)==FALSE){
dir.create(result.folder)
}
if(length(dir(result.folder))> 0)
print("Warning! Your result.folder has something in it. Those files will be overwritten!")
# bring in the age and birth and death rate data
if(file.exists(birthdeath.file)==FALSE)
stop("You didn't provide an existing file for birthdeath.file!")
d <- read.csv(file = birthdeath.file, colClasses = c("numeric", "numeric", "numeric", "numeric"))
if(ncol(d)!= 4)
stop("Your birthdeath.file does not have 4 columns. The columns should be age, ageClass, birthRate, and survivalRate, in that order.")
colnames(d) <- c("age", "ageClass", "birthRate", "survivalRate") #set column names of the age class, vitals data
maxAgeClass=max(d$ageClass) #max age class in order to get a proportion of age class for age class based rates of naive learning
#create starting individual w attributes ("alive", "age", "informed"), initial population
print("Creating initial individual database.")
if(set_seed){
set.seed(1)
}
ind <- vector(mode="list", N0)
for(i in seq(ind)){
ind[[i]]$alive <- 1 #0 if false, 1 if true
ind[[i]]$sex <- rbinom(1, 1, sex.ratio) #coinflip for sex, 0 = male, 1 = female
ind[[i]]$age <- rpois(1, age.distr.lamba) #poisson distribution of age centered around 5
if(ind[[i]]$age==0){   #can't have a 0
ind[[i]]$age <- 1
}
informedProb <- rbeta(1, informed.distr.beta[1], informed.distr.beta[2]) #probability of knowing information, beta distribution ranges from 0 to 1
ageClass <- d$ageClass[which(d$age == ind[[i]]$age)]
ind[[i]]$informed <- round((informedProb + informedProb * (ageClass/maxAgeClass))/2) #0 if false, 1 if true, modified by age class proportion (we standardize so the values range from 0 to 1, based on the range could be 0 to 2)
ind[[i]]$boldness <- rbeta(1, bold.distr.beta[1], bold.distr.beta[2]) #beta distribution, ranges from 0 to 1
ind[[i]]$mother <- 0
ind[[i]]$birthYr <- 0
#ind[[i]]$maternalSurvivalMod <- rbeta(1, .8, 1)
}
interactionMatrix <- Matrix(data = 0,
nrow = length(seq(ind)),
ncol = length(seq(ind)), sparse = TRUE)
#make empty vectors to record population statistics for each time step
time <- seq(t+1)
pop <- list() # population size
pop[[1]] <- which(sapply(ind, function(x) x$alive) == 1)
frac.informed <- NaN * time # fraction of population that is informed
info <- sapply(ind, function(x) x$informed)
frac.informed[1] <- mean(info)
med.age <- NaN * time
ages <- sapply(ind, function(x) x$age)
med.age[1] <- median(ages)
interactions <- list()
interactions[[1]] <- interactionMatrix
#this dataframe will be saved out at every t iteration no matter what.
tosave <- data.frame(time.stamp=Sys.time(), t=0, pop.size=length(pop[[1]]),births=NA, deaths=NA,
frac.informed=frac.informed[1], med.age=med.age[1])
#simulation starts here
print(paste0("Looping through the ", t, " years."))
for(i in seq(t)){ # loop for each time increment
#prep that years data
# print(i)
is.alive <- which(sapply(ind, function(x) x$alive) == 1) #just alive individuals from total list
boldness <- sapply(ind[is.alive], function(x) x$boldness) #boldness of alive individuals
interactionMatrix <- Matrix(data = 0,   #build a new interaction matrix for this time step!
nrow = length(seq(is.alive)),
ncol = length(seq(is.alive)), sparse = TRUE)
for(j in is.alive){ #loop for each alive individual
# print(j)
curIndividual <- ind[[j]] #assigns current individual
indexJ <- which(is.alive == j)
ageClass <- d$ageClass[which(d$age == curIndividual$age)] #age class of current
birthRate <- d$birthRate[which(d$age == curIndividual$age)] #birth rate of current age class
survivalRate <- d$survivalRate[which(d$age == curIndividual$age)] #survival rate of current age class
curIndividual$informed <- rbinom(1, 1, nl * ageClass/maxAgeClass * (1-curIndividual$informed)) # calculate a naive learning probability, depends on age class
socialPool <- data.frame(is.alive[-indexJ], boldness[-indexJ]) #pool of available individuals to socialize with
socialPool$numInteractions <- rpois(nrow(socialPool), (si * curIndividual$boldness * ifelse(length(is.alive)>=K, 1, length(is.alive)/K) * socialPool$boldness))# calculate a social interaction probability for each individual that is alive
colnames(socialPool) <- c("is.alive", "boldness", "numInteractions")
socialPool$intIDinformed <- sapply(ind[socialPool$is.alive], function(x) x$informed)
interactionMatrix[-indexJ,indexJ] <- socialPool$numInteractions #update interaction matrix
interactionMatrix[indexJ,-indexJ] <- socialPool$numInteractions #update interaction matrix
socialPool$calc <- ifelse(curIndividual$informed==0 & socialPool$intIDinformed == 0, 0, 1)
socialPool$infotranser <- do.call(c, lapply(1:nrow(socialPool), function(ii){
return(ifelse(sum(rbinom(socialPool$numInteractions[ii], 1, infotransfer))>0,1,0))
}))
socialPool$infotranser <- socialPool$infotranser*socialPool$calc
if(curIndividual$informed==0 & sum(socialPool$infotranser)>0){   #if status is 0 or there was an interaction wher info was transfered, then put a 1 in there
curIndividual$informed <- 1
}
socialPool$infotranser <- ifelse(socialPool$intIDinformed+socialPool$infotranser>0,1,0)  # now we need to update the interacting individuals and their info status
for(g in 1:nrow(socialPool)){ #loop through interaction individuals
indexG <- socialPool$is.alive[g]
ind[[indexG]]$informed <- socialPool$infotranser[g] #update current interaction individual in total individuals dataset
}
# birth section
birth <- birthRate + birthRate * (1 - length(is.alive)/K) # calculate a birth probability for each individual that is alive
birth <- rbinom(1,1, ifelse(birth<=0,0,ifelse(birth>1,1,birth)))
if(birth==1 && (ind[[j]]$sex == 1)){ #checks for succesful birth and female sex
#create new individual
len.ind <- length(ind)
informedProb <- rbeta(1, informed.distr.beta[1], informed.distr.beta[2])
ind[[len.ind+1]] <- list(alive=1, age=1, sex = rbinom(1, 1, sex.ratio),
informed=ifelse(vertTransmission==1, ind[[j]]$informed,
rbeta(1, informed.distr.beta[1], informed.distr.beta[2])),
boldness = rbeta(1, bold.distr.beta[1], bold.distr.beta[2]),
mother = j, birthYr = i) # create offspring, inherits informed status of parent
}
#death decided by survival Rate, density, and increased uniformed mortality rate
death <- 1- (survivalRate + survivalRate*(1 - (length(is.alive)/K)) - ((1 - curIndividual$informed) * h)) # calculate a death probability for each individual
death <- rbinom(1,1, ifelse(death>1,1,ifelse(death<0,0,death)))
if(death==1){
curIndividual$alive <- 0 # if death, reset alive = 0
} else { #else, advance age + 1
curIndividual$age <- curIndividual$age + 1 # advance age of parent
}
ind[[j]] <- curIndividual #update current individual in the total ind list
}
#optional cropping of list "ind"
# if(save.alive.only){
#   is.dead <- which(sapply(ind, function(x) x$alive) == 0)
#   if(length(is.dead) > 0) ind <- ind[-is.dead]
# }
# saving Population stats for final output
numb.died <- length(which(sapply(ind[is.alive], function(x) x$alive) == 0))
is.alive <- which(sapply(ind, function(x) x$alive) == 1)
pop[[i+1]] <- is.alive
info <- sapply(ind, function(x) x$informed)
frac.informed[i+1] <- sum(info[is.alive]  == 1) / length(is.alive)
ages <- sapply(ind, function(x) x$age)
med.age[i+1] <- median(ages[is.alive])
interactions[[i+1]] <- interactionMatrix
tosave <- rbind(tosave, data.frame(time.stamp=Sys.time(), t=i, pop.size=length(pop[[i+1]]),frac.informed=frac.informed[i+1],
births=length(which(sapply(ind, function(x) x$birthYr) == i)),
deaths=numb.died, med.age=med.age[i+1]))
write.csv(tosave, paste0(result.folder,"/population_stats.csv"), row.names = FALSE)
#save out all the main files?
if(save_at_each_iter){
save(interactions, file = paste0(result.folder,"/interaction_matricies.RData"))
save(pop, file = paste0(result.folder,"/population_data.RData"))  #don't really need this if ind data is written out
save(ind, file = paste0(result.folder,"/individual_data.RData"))
}
#simulation progress
Sys.sleep(.1)
print(paste0(i, " of ", t, " finished ", "[", round(i/t*100,0), "%]"))
} # end of loop through t
#write out final files
write.csv(tosave, paste0(result.folder,"/population_stats.csv"), row.names = FALSE)
save(interactions, file = paste0(result.folder,"/interaction_matricies.RData"))
save(pop, file = paste0(result.folder,"/population_data.RData"))  #don't really need this if ind data is written out
save(ind, file = paste0(result.folder,"/individual_data.RData"))
#time to run simulation
return(paste0("Completed in ", round((as.numeric(Sys.time())-as.numeric(t1))/60,2), " mins! Check your result.folder for results."))
}
bold.distr.beta=c(2, 5)
plot(bold.distr.beta)
plot(rbeta(10000, bold.distr.beta))
plot(rbeta(10000, 2,5))
hist(rbeta(1000, 2,5))
table(rpois(10000, 5))
66/10000
table(rpois(10000, 4))
table(rpois(10000, 5))
table(rpois(10000, 3))
seq(0, length(is.alive)+1, 0)
seq(0, 50+1, 0)
vector(numeric, 54)
vector("numeric", 54)
